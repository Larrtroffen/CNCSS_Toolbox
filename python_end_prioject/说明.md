# task1

---
因为🐟烧饼可见的爬完数据看都不看一眼，所以数据清洗部分稍微麻烦一点，可视化部分我没有认真做，所以可以随便改。

情感分析我不知道你们用的是什么包，我这里随便拿了一个snownlp（接近1越积极，接近0越消极），你们可以改。

地图，可见的他选了武汉周边那一个框，所以我用的是湖北省地图，实在是懒得裁了，可以换标准的方形地图，参见阿里的地图服务和天地图。

我没观察到有什么规律。可以通过更换可视化方式来观察。

# task2

---
这个我用的是桂林的政府工作报告。十年的链接分别放在`urls.txt`中，从上到下分行依次为2024-2015。若要换其他城市，直接修改即可。

若要修改的话，链接建议采用政府信息公开→政府工作报告部分。

修改完成后可以直接运行`gov_spider.py`爬取数据。将爬取的文档放入gov中即可。

技术路线依然是结巴分词，词表`stopwords.txt`停词，然后TF-TDF，k-means聚类。

词云图使用的是Wordcloud，字体是宋体，换字体的话，路径可以自己改。